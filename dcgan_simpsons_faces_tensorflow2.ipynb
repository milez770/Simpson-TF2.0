{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"dcgan_simpsons_faces_tensorflow2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python [conda env:.conda-gantest-gpu2] *","language":"python","name":"conda-env-.conda-gantest-gpu2-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"e1_Y75QXJS6h"},"source":["### Import TensorFlow2 and other libraries"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J5oue0oqCkZZ","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FkpJAKcoF4dE","colab_type":"text"},"source":["구글 드라이브를 마운트하고, 패키지를 설치할 경로를 설정합니다.\n","\n","/content/mnt/My Drive/Colab Notebooks/packages 폴더를 먼저 만들고, content/notebooks/packages라는 경로에 매핑합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"kNQHu6XmFxqz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"outputId":"9ea3d4d6-082f-40d1-a947-ef0ec3753844","executionInfo":{"status":"ok","timestamp":1576976608906,"user_tz":-540,"elapsed":22039,"user":{"displayName":"유원선","photoUrl":"","userId":"18141112582189658729"}}},"source":["import os\n","import sys\n","from google.colab import drive\n","drive.mount('/content/mnt')\n","# drive.mount(\"/content/mnt\", force_remount=True)\n","nb_path = '/content/notebooks_packages'\n","sys.path.insert(0, nb_path)\n","os.symlink('/content/mnt/My Drive/Colab Notebooks/packages', nb_path)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/mnt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xFF4KQxUHzDk","colab_type":"text"},"source":["텐서플로우 2.0 gpu버전을 nb-path에 설치합니다. 최초 한번만 실행하고 이후부터는 이 라인은 스킵해서 실행합니다.\n","\n","설치한 뒤에 런타임을 한번 재시작해줍니다.\n","\n","로컬 런타임이었다면\n","\n","!pip install Pillow \n","\n","!pip install matplotlib \n","\n","!pip install imageio \n","\n","!pip install opencv-python\n","\n","\n","도 함께 실행해야했겠지만, Colab에 이미 설치되어있으므로 스킵합니다."]},{"cell_type":"code","metadata":{"id":"TvC1i_HGHvlR","colab_type":"code","colab":{}},"source":["!pip install --target=$nb_path --upgrade tensorflow-gpu==2.0.0-beta1\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gjui5txlJGYp","colab_type":"text"},"source":["import를 실행하면 시간이 좀 걸린뒤 완료됩니다. (10~20분)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WZKbyU2-AiY-","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IPkf-TDHIV_D","colab_type":"text"},"source":["텐서플로우 버전과 사용하고 있는 GPU 이름을 확인하여 정상적으로 설치되고, 적합한 세션을 사용하고 있는지 확인합니다.\n","\n","2.0.0-beta1\n","GPU name : ~~~\n","\n","이 출력되면 정상 세팅된 상태입니다."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wx-zNbLqB4K8","colab":{"base_uri":"https://localhost:8080/","height":244},"outputId":"00657ab4-9b6b-40be-8eb5-d723b75cb2cb","executionInfo":{"status":"error","timestamp":1576976651800,"user_tz":-540,"elapsed":1071,"user":{"displayName":"유원선","photoUrl":"","userId":"18141112582189658729"}}},"source":["print(tf.__version__)\n","\n","from tensorflow.python.client import device_lib\n","\n","\"GPU\" + device_lib.list_local_devices()[-1].physical_device_desc.split(\",\")[1]"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-825449dce4d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\"GPU\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphysical_device_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"R_dywCfwFvqE","colab_type":"text"},"source":["나머지 필요한 패키지 세팅"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YfIk2es3hJEd","colab":{}},"source":["import time\n","import datetime\n","import random\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from glob import glob\n","import imageio\n","from PIL import Image\n","import cv2\n","import PIL\n","\n","from IPython import display\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TUxh3Kz0FvqH","colab_type":"code","colab":{}},"source":["os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iYn4MdZnKCey"},"source":["### 데이터셋을 로드하고 학습가능한 형태로 정리합니다.\n","\n","OUTPUT_DIR를 설정할 때, 잘못설정하면 수정하기 아주 귀찮은 디렉토리에 저장되기 때문에 항상 확인하고 학습을 진행하도록 합니다."]},{"cell_type":"code","metadata":{"id":"YHhKKH_dFvqK","colab_type":"code","colab":{}},"source":["# Paths Setting\n","INPUT_DATA_DIR = '/content/mnt/My Drive/Colab Notebooks/dataset/simpson/'\n","OUTPUT_DIR = '/content/mnt/My Drive/Colab Notebooks/results/simpson/output_{date:%Y-%m-%d_%H%M%S}/'.format(date=datetime.datetime.now())\n","# OUTPUT_DIR = '/content/mnt/My Drive/Colab Notebooks/results/simpson/output_2019-12-20_024720/'\n","\n","OUTPUT_LOSS_DIR = OUTPUT_DIR + 'loss/'\n","OUTPUT_IMG_DIR = OUTPUT_DIR + 'images/'\n","OUTPUT_WEIGHT_DIR = OUTPUT_DIR + 'weight/'\n","\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n","\n","if not os.path.exists(OUTPUT_LOSS_DIR):\n","    os.makedirs(OUTPUT_LOSS_DIR)\n","\n","if not os.path.exists(OUTPUT_IMG_DIR):\n","    os.makedirs(OUTPUT_IMG_DIR)\n","    \n","if not os.path.exists(OUTPUT_WEIGHT_DIR):\n","    os.makedirs(OUTPUT_WEIGHT_DIR)    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AxtNUj05MF73","colab_type":"text"},"source":["추론률을 떨어트리는 데이터셋을 제외하고 파일을 로드합니다"]},{"cell_type":"code","metadata":{"id":"K86kmdxWFvqM","colab_type":"code","colab":{}},"source":["exclude_file_list = [\"9746\",\"9731\",\"9717\",\"9684\",\"9637\",\"9641\",\"9642\",\"9584\",\"9541\",\"9535\",\n","                     \"9250\",\"9251\",\"9252\",\"9043\",\"8593\",\"8584\",\"8052\",\"8051\",\"8008\",\"7957\",\n","                     \"7958\",\"7761\",\"7762\",\"9510\",\"9307\",\"4848\",\"4791\",\"4785\",\"4465\",\"2709\",\n","                     \"7724\",\"7715\",\"7309\",\"7064\",\"7011\",\"6961\",\"6962\",\"6963\",\"6960\",\"6949\",\n","                     \"6662\",\"6496\",\"6409\",\"6411\",\"6406\",\"6407\",\"6170\",\"6171\",\"6172\",\"5617\",\n","                     \"4363\",\"4232\",\"4086\",\"4047\",\"3894\",\"3889\",\"3493\",\"3393\",\"3362\",\"2780\",\n","                     \"2710\",\"2707\",\"2708\",\"2711\",\"2712\",\"2309\",\"2056\",\"1943\",\"1760\",\"1743\",\n","                     \"1702\",\"1281\",\"1272\",\"772\",\"736\",\"737\",\"691\",\"684\",\"314\",\"242\",\"191\"]\n","\n","for ex_image in exclude_file_list:\n","    if os.path.exists(f'{INPUT_DATA_DIR}{ex_image}.png'):\n","        print(f'{INPUT_DATA_DIR}{ex_image}.png')\n","        os.rename(f'{INPUT_DATA_DIR}{ex_image}.png', f'{INPUT_DATA_DIR}{ex_image}.png_bak')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9dQPdVh2MSvd","colab_type":"text"},"source":["학습에 사용될 하이퍼 파라미터들\n","\n","가장 어려운 부분이 시작된다! 컨볼루션(합성곱) 네트워크 용어를 이해하고 넘어가보자\n","\n","**합성곱(convolution)**\n","\n","이렇게 부분부분을 곱해서 정리하는 것을 합성곱이라고 한다.\n","![합성곱 작동 원리](https://studio-velcro.com/img/Convolution_schematic.gif)\n","\n","**채널**\n","\n","RGB할 때 그런 채널. 이미지뿐만 아니라 여러가지 모든 레이어는 다 채널로 표현한다.\n","\n","**필터 & 스트라이드**\n","\n","필터는 이미지에서 feature map을 뽑아낼 틀을 이야기함. 보통 정사각형 모양을 가진다. 합성곱에 있는 gif참조.\n","![대체 텍스트](https://studio-velcro.com/img/conv_filter.png)\n","스트라이드(stride)는 필터를 몇칸씩 움직이며 feature map을 작성할 것인가를 결정하는 파라미터. 1이면 1칸씩 2면 2칸씩 ....\n","\n","멀티채널의 경우 아래와같이 계산해서 이미지에 대한 최종적인 feature map을 만들어낸다.\n","![대체 텍스트](https://studio-velcro.com/img/conv2_filter_multichannel.jpg)\n","\n","**패딩**\n","\n","feature map을 만들고나면 결과물은 실제 이미지보다 사이즈가 작아지게 된다! 이미지 사이즈를 맞춰주기위해 feature map 주변에 0(보통 0임)으로 둘러 사이즈를 맞추게 된다. 이미지 외곽을 학습시키는 부가효과도 있다.\n","![대체 텍스트](https://studio-velcro.com/img/padding.png)\n","\n","**pooling**\n","\n","출력 데이터를 강조하거나 크기를 줄이는 데 사용한다. 그런게 있다 정도만 이해하면 될듯.\n","CNN에서는 주로 Max Pooling을 사용한다.\n","![대체 텍스트](https://studio-velcro.com/img/maxpooling.png)\n","\n","용어는 여기까지 알아보고 더 자세한 내용은 좀 이따 제너레이터/디스크리미네이터 짤 때 추가로 알아보자\n","\n","배치사이즈 64 : 한번에 몇장의 이미지를 학습할 것인가 -> 64장씩 학습할거다.\n"]},{"cell_type":"code","metadata":{"id":"k2_Sh5-ZFvqQ","colab_type":"code","colab":{}},"source":["# Hyperparameters\n","IMAGE_SIZE = 128\n","NOISE_SIZE = 100\n","LR_D = 0.00004\n","LR_G = 0.0004\n","BATCH_SIZE = 64\n","EPOCHS = 300\n","BETA1 = 0.5\n","WEIGHT_INIT_STDDEV = 0.02\n","EPSILON = 0.00005\n","SAMPLES_TO_SHOW = 16    # 5 > 16\n","BUFFER_SIZE = 1000     # 10240 ?"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xz0_CY0bMa5M","colab_type":"text"},"source":["이미지에 적용할 노이즈를 생성합니다.\n","16x100 형태의 노이즈 생성\n","\n","16: 샘플 이미지 갯수\n","\n","100: 노이즈 사이즈"]},{"cell_type":"code","metadata":{"id":"Oqe3XoKRFvqS","colab_type":"code","colab":{}},"source":["display_noise = tf.random.uniform(shape=[SAMPLES_TO_SHOW, NOISE_SIZE], minval=-1, maxval=1, dtype=tf.dtypes.float32)\n","print(display_noise.shape)\n","\n","w_init = tf.initializers.TruncatedNormal(stddev=WEIGHT_INIT_STDDEV)\n","w_init"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mgkDrv77FvqV","colab_type":"code","colab":{}},"source":["def load_data(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_png(img)\n","    img = tf.image.resize(img, size=[IMAGE_SIZE, IMAGE_SIZE])[..., :3]\n","    img /= 127.5\n","    img -= 1\n","    return img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"35cjKP3gFvqX","colab_type":"code","colab":{}},"source":["image_list = glob(INPUT_DATA_DIR + '*.png')\n","print('Found {} images'.format(len(image_list)))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ST7A_AlBFvqZ","colab_type":"code","colab":{}},"source":["image_dataset = tf.data.Dataset.from_tensor_slices(image_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-QA6419Fvqb","colab_type":"code","colab":{}},"source":["image_dataset = image_dataset.shuffle(buffer_size=BUFFER_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-GkATIQFvqf","colab_type":"code","colab":{}},"source":["image_dataset = image_dataset.map(load_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-YlistdFvqi","colab_type":"code","colab":{}},"source":["image_dataset = image_dataset.batch(BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ad4hnKkCFvqk","colab_type":"code","colab":{}},"source":["image_dataset = image_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"THY-sZMiQ4UV"},"source":["## Create the models\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-tEyxE-GMC48"},"source":["### The Generator (더 어려운 이야기의 시작)\n","\n","레이어 사이즈를 결정할 때는 공식에 따라야한다. 그냥 파라미터를 어떻게 정하면 어떻게 출력된다를 정리한거니까 이해하려고하지 말자.\n","\n","입력 데이터 -> 필터+스트라이드+패딩 -> 출력 데이터\n","\n","*   입력 데이터 높이: H\n","*   입력 데이터 폭: W\n","*   필터 높이: FH\n","*   필터 폭: FW\n","*   Stride 크기: S\n","*   패딩 사이즈: P\n","![대체 텍스트](https://studio-velcro.com/img/conv_equation.png)\n","\n","이 식의 결과는 모두 **자연수**여야한다. 컨볼루션 레이어 뒤에 풀링 레이어가 오면 Feature Map의 행과 열 크기는 Pooling 크기의 배수여야 한다. Pooling 사이즈가 (3, 3)이라면 위 식의 결과는 자연수이고 3의 배수여야 한다. 이 조건을 만족하도록 필터와 stride, pooling 사이즈를 조정해야한다. 왜냐? 안맞으면 데이터가 안들어간다!\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6bpTcDqoLWjY","colab":{}},"source":["def make_generator_model(generator_dim=100):\n","    \n","    noise = tf.keras.layers.Input(shape=(generator_dim,), name='generator_noise_input')\n","    \n","    # 1024x8x8 = 262,144\n","    x = tf.keras.layers.Dense(8*8*1024)(noise)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.layers.LeakyReLU()(x)\n","    # 8x8x1024\n","    x = tf.keras.layers.Reshape(target_shape=[8, 8, 1024])(x)\n","    print(x.shape)\n","    \n","    # 1. 16x16x1024 -> 32x32x512\n","    x = tf.keras.layers.Conv2DTranspose(filters=512,\n","                                        kernel_size=5,\n","                                        strides=2,\n","                                        padding='same',\n","                                        kernel_initializer=w_init,\n","                                        use_bias=True)(x)\n","    x = tf.keras.layers.BatchNormalization(epsilon=EPSILON)(x)\n","    x = tf.keras.layers.ReLU()(x)\n","    print(x.shape)\n","    \n","    # 2. 32x32x512 -> 64x64x256\n","    x = tf.keras.layers.Conv2DTranspose(filters=256,\n","                                        kernel_size=5,\n","                                        strides=2, \n","                                        padding='same',\n","                                        kernel_initializer=w_init,\n","                                        use_bias=True)(x)\n","    x = tf.keras.layers.BatchNormalization(epsilon=EPSILON)(x)\n","    x = tf.keras.layers.ReLU()(x)\n","    print(x.shape)\n","    \n","    # 3. 64x64x256 -> 128x128x128\n","    x = tf.keras.layers.Conv2DTranspose(filters=128,\n","                                        kernel_size=5,\n","                                        strides=2, \n","                                        padding='same',\n","                                        kernel_initializer=w_init,\n","                                        use_bias=True)(x)\n","    x = tf.keras.layers.BatchNormalization(epsilon=EPSILON)(x)\n","    x = tf.keras.layers.ReLU()(x)\n","    print(x.shape)\n","    \n","    # 4. 128x128x128 -> 256x256x64\n","    x = tf.keras.layers.Conv2DTranspose(filters=64,\n","                                        kernel_size=5,\n","                                        strides=2, \n","                                        padding='same',\n","                                        kernel_initializer=w_init,\n","                                        use_bias=True)(x)\n","    x = tf.keras.layers.BatchNormalization(epsilon=EPSILON)(x)\n","    x = tf.keras.layers.ReLU()(x)\n","    print(x.shape)\n","    \n","    # 256x256x64 -> 512x512x32\n","    # 256x256x64 -> 512x512x3\n","    x = tf.keras.layers.Conv2DTranspose(filters=3,\n","                                        kernel_size=5,\n","                                        strides=1, \n","                                        padding='same',\n","                                        kernel_initializer=w_init,\n","                                        use_bias=True)(x)\n","    print(x.shape)\n","    \n","    fake_output = tf.keras.layers.Activation('tanh', name='logits')(x)\n","    print(fake_output)\n","    \n","    return tf.keras.Model(inputs=[noise], outputs=[fake_output], name='Generator')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gl7jcC7TdPTG","scrolled":false,"colab":{}},"source":["generator = make_generator_model(NOISE_SIZE)\n","\n","generated_image = generator(display_noise, training=False)\n","print (\"Input: \" + str(generated_image.shape))\n","\n","images = tf.clip_by_value((generated_image + 1) * 127.5, 0, 255).numpy()\n","for i in range(16):\n","    cv2.imwrite(f'{OUTPUT_IMG_DIR}generated_noise_{i}.png', cv2.cvtColor(images[i], cv2.COLOR_RGB2BGR))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"D0IKnaCtg6WE"},"source":["### The Discriminator\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dw2tPLmk2pEP","colab":{}},"source":["def make_discriminator_model(latent_dim=100):\n","    \n","    image_input = tf.keras.layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, 3], name='discriminator_image_input')\n","    print(image_input.shape)\n","    \n","    # 128*128*3 -> 64x64x64 \n","    x = tf.keras.layers.Conv2D(filters=64,\n","                               kernel_size=5,\n","                               strides=2, \n","                               padding='same',\n","                               kernel_initializer=w_init,\n","                               use_bias=True)(image_input)\n","    x = tf.keras.layers.BatchNormalization(epsilon=EPSILON)(x)\n","    x = tf.keras.layers.LeakyReLU()(x)\n","    print(x.shape)\n","    \n","    # 64x64x64-> 32x32x128 \n","    x = tf.keras.layers.Conv2D(filters=128,\n","                               kernel_size=5,\n","                               strides=2, \n","                               padding='same',\n","                               kernel_initializer=w_init,\n","                               use_bias=True)(x)\n","    x = tf.keras.layers.BatchNormalization(epsilon=EPSILON)(x)\n","    x = tf.keras.layers.LeakyReLU()(x)\n","    print(x.shape)\n","\n","    # 32x32x128 -> 16x16x256  \n","    x = tf.keras.layers.Conv2D(filters=256,\n","                               kernel_size=5,\n","                               strides=2, \n","                               padding='same',\n","                               kernel_initializer=w_init,\n","                               use_bias=True)(x)\n","    x = tf.keras.layers.BatchNormalization(epsilon=EPSILON)(x)\n","    x = tf.keras.layers.LeakyReLU()(x)\n","    print(x.shape)\n","\n","    # 16x16x256 -> 16x16x512\n","    x = tf.keras.layers.Conv2D(filters=512,\n","                               kernel_size=5,\n","                               strides=1, \n","                               padding='same',\n","                               kernel_initializer=w_init,\n","                               use_bias=True)(x)\n","    x = tf.keras.layers.BatchNormalization(epsilon=EPSILON)(x)\n","    x = tf.keras.layers.LeakyReLU()(x)\n","    print(x.shape)\n","    \n","    # 16x16x512 -> 8x8x1024\n","    x = tf.keras.layers.Conv2D(filters=1024,\n","                               kernel_size=5,\n","                               strides=2,\n","                               padding='same',\n","                               kernel_initializer=w_init,\n","                               use_bias=True)(x)\n","    x = tf.keras.layers.BatchNormalization(epsilon=EPSILON)(x)\n","    x = tf.keras.layers.LeakyReLU()(x)\n","    print(x.shape)\n","    \n","    x = tf.keras.layers.Reshape(target_shape=(-1, 8*8*1024))(x)\n","    logits = tf.keras.layers.Dense(units=1, activation=None)(x)\n","    print(logits)\n","    \n","    return tf.keras.Model(inputs=[image_input], outputs=[logits], name='Discriminator')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gDkA05NE6QMs","colab":{}},"source":["discriminator = make_discriminator_model()\n","decision = discriminator(generated_image)\n","print (decision.shape)\n","#print (decision)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0FMYgY_mPfTi"},"source":["## Define the loss and optimizers\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PKY_iPSPNWoj"},"source":["### Discriminator loss\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wkMNfBWlT-PV","colab":{}},"source":["def d_loss_real_function(d_logits_real):\n","    \n","    # Discriminator logic\n","    d_model_real = tf.sigmoid(d_logits_real)\n","    \n","    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n","                                                                         labels=tf.ones_like(d_model_real)*random.uniform(0.9, 1.0)))\n","    \n","    return d_model_real, d_loss_real\n","\n","\n","def d_loss_fake_function(d_logits_fake):\n","    \n","    # Discriminator logic\n","    d_model_fake = tf.sigmoid(d_logits_fake)\n","    \n","    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n","                                                                         labels=tf.zeros_like(d_model_fake)))\n","    \n","    return d_model_fake, d_loss_fake"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Jd-3GCUEiKtv"},"source":["### Generator loss\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"90BIcCKcDMxz","colab":{}},"source":["def g_loss_function(d_logits_fake, d_model_fake):\n","    \n","    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n","                                                                    labels=tf.ones_like(d_model_fake)))\n","    return g_loss\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MgIc7i0th_Iu"},"source":["### optimizers\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iWCn_PVdEJZ7","colab":{}},"source":["d_optimizer = tf.keras.optimizers.Adam(learning_rate=LR_D, beta_1=BETA1)\n","g_optimizer = tf.keras.optimizers.Adam(learning_rate=LR_G, beta_1=BETA1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mWtinsGDPJlV"},"source":["### Save checkpoints\n","\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CA1w-7s2POEy","colab":{}},"source":["checkpoint_dir = OUTPUT_DIR + 'training_checkpoints'\n","\n","if not os.path.exists(checkpoint_dir):\n","    os.makedirs(checkpoint_dir)    \n","\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(generator_optimizer=g_optimizer,\n","                                 discriminator_optimizer=d_optimizer,\n","                                 generator=generator,\n","                                 discriminator=discriminator)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Rw1fkAczTQYh"},"source":["## Define the training loop\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NS2GWywBbAWo","colab":{}},"source":["print(display_noise)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3t5ibNo05jCB","colab":{}},"source":["@tf.function\n","def training_step(images):\n","    \n","    noise = tf.random.uniform(shape=[BATCH_SIZE, NOISE_SIZE], minval=-1, maxval=1, dtype=tf.dtypes.float32)\n","\n","    with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape, tf.GradientTape() as r_tape:\n","\n","        # noise generator > discriminator\n","        g_model = generator(noise, training=True)\n","        \n","        d_logits_fake = discriminator(g_model, training=True)\n","        \n","        d_model_fake, d_loss_fake = d_loss_fake_function(d_logits_fake)\n","        \n","        \n","        # noise readl > discriminator \n","        noisy_input_real = images + tf.random.normal(shape=tf.shape(images),\n","                                                     mean=0.0,\n","                                                     stddev=random.uniform(0.0, 0.1),\n","                                                     dtype=tf.dtypes.float32)\n","        \n","        d_logits_real = discriminator(noisy_input_real, training=True)\n","        \n","        d_model_real, d_loss_real = d_loss_real_function(d_logits_real)\n","\n","        \n","        # discriminator loss\n","        d_loss = tf.reduce_mean(0.5 * (d_loss_real + d_loss_fake))\n","        \n","        # generator loss\n","        g_loss = g_loss_function(d_logits_fake, d_model_fake)\n","\n","        discriminator_gradients_fake = d_tape.gradient(d_loss, discriminator.trainable_variables)\n","        generator_gradients = g_tape.gradient(g_loss, generator.trainable_variables)\n","\n","        d_optimizer.apply_gradients(zip(discriminator_gradients_fake, discriminator.trainable_variables))\n","        g_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n","\n","    return g_loss, d_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2M7LmLtGEMQJ","colab":{}},"source":["def train(epochs=10, save_every=3, steps=None):\n","    \n","    d_losses = []\n","    g_losses = []\n","    summary_step = 0\n","    \n","    for ep in range(epochs):\n","        \n","        start = time.time()\n","        \n","        running_loss = {'g_loss': [], 'd_loss': []}\n","        for step, images in enumerate(image_dataset):\n","            \n","            batch_g_loss, batch_d_loss = training_step(images)\n","            \n","            # loss write\n","            d_losses.append(batch_d_loss.numpy())\n","            g_losses.append(batch_g_loss.numpy())\n","            \n","            if step % 10 == 0:\n","                ctime = time.strftime(\"%Y/%m/%d/ %H:%M:%S\")\n","                print(f'||epoch {ep}/{epochs} step {step+1}/{steps}|G_LOSS : {batch_g_loss:.3f}|D_LOSS : {batch_d_loss:.3f}|| {ctime}' )\n","            \n","            tf.summary.scalar(\"generator_batch_loss\", batch_g_loss, step=summary_step + 1)\n","            tf.summary.scalar(\"discriminator_batch_loss_total\", batch_d_loss, step=summary_step + 1)\n","            writer.flush()\n","            \n","            summary_step = summary_step + 1\n","        \n","        if ep % save_every == 0:\n","            print(f'||saving weights for epoch : {ep}||')\n","            generator.save_weights(f'{OUTPUT_WEIGHT_DIR}generator_weights_{ep}.h5')\n","            discriminator.save_weights(f'{OUTPUT_WEIGHT_DIR}discriminator_weights_{ep}.h5')\n","            checkpoint.save(file_prefix = checkpoint_prefix)\n","        \n","        display.clear_output(wait=True)\n","        print ('Time for epoch [{}] is [{}] sec'.format(ep, time.time()-start))\n","\n","        # test noise not change for gif gen\n","        #display_noise = tf.random.uniform(shape=[SAMPLES_TO_SHOW, NOISE_SIZE], minval=-1, maxval=1, dtype=tf.dtypes.float32)\n","        save_generated_images(display_noise, epoch=ep)\n","        \n","        summarize_epoch(ep, time.time()-start, d_losses, g_losses)\n","            \n","    return d_losses, g_losses"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2aFF7Hk3XdeW"},"source":["**Generate and save images**\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"mItJovrfFvrP","colab_type":"code","colab":{}},"source":["def save_generated_images(noise, epoch=None):\n","    \n","    images_result = generator(noise)\n","    \n","    # cv \n","    images = tf.clip_by_value((images_result + 1) * 127.5, 0, 255).numpy()\n","    for i in range(16):\n","        cv2.imwrite(f'{OUTPUT_IMG_DIR}{i}_{epoch}.png', cv2.cvtColor(images[i], cv2.COLOR_RGB2BGR))\n","    \n","    # plt\n","    sample_images = [tf.cast((sample + 1) * 127.5, dtype=tf.uint8).numpy() for sample in images_result]\n","    fig = plt.figure(figsize=(6,6)) \n","\n","    for i in range(16):\n","        plt.subplot(4, 4, i+1)\n","        plt.imshow(sample_images[i])\n","        plt.axis('off')\n","    plt.savefig(OUTPUT_DIR + 'image_at_epoch_{:04d}.png'.format(epoch))\n","    plt.show()\n","    plt.close()\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0cJeDUIFvrU","colab_type":"code","colab":{}},"source":["def summarize_epoch(epoch, duration, d_losses, g_losses):\n","    \n","    minibatch_size = int(len(image_list)//BATCH_SIZE)\n","    \n","    print(\"Epoch {}/{}\".format(epoch, EPOCHS),\n","          \"\\nDuration: {:.5f}\".format(duration),\n","          \"\\nD Loss: {:.5f}\".format(np.mean(d_losses[-minibatch_size:])),\n","          \"\\nG Loss: {:.5f}\".format(np.mean(g_losses[-minibatch_size:])))\n","    \n","    fig, ax = plt.subplots()\n","    plt.plot(d_losses, label='Discriminator', alpha=0.6)\n","    plt.plot(g_losses, label='Generator', alpha=0.6)\n","    plt.title(\"Losses\")\n","    plt.legend()\n","    plt.savefig(OUTPUT_LOSS_DIR + \"losses_\" + str(epoch) + \".png\")\n","    plt.show()\n","    plt.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dZrd4CdjR-Fp"},"source":["## Train the model\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ly3UN0SLLY2l","scrolled":false,"colab":{}},"source":["%%time\n","writer = tf.summary.create_file_writer(OUTPUT_DIR + 'logs')\n","with writer.as_default():\n","    steps_per_epoch = len(image_list)//BATCH_SIZE\n","    d_losses, g_losses = train(EPOCHS, 10, steps_per_epoch)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rfM4YcPVPkNO"},"source":["## Restore the latest checkpoint."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XhXsd0srPo8c","colab":{}},"source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"P4M_vIbUi7c0"},"source":["## Create a GIF\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WfO5wCdclHGL","colab":{}},"source":["# Display a single image using the epoch number\n","def display_image(epoch_no):\n","    return PIL.Image.open('{}image_at_epoch_{:04d}.png'.format(OUTPUT_DIR, epoch_no))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5x3q9_Oe5q0A","scrolled":false,"colab":{}},"source":["display_image(0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2J4XuYlW6FdO","colab_type":"text"},"source":["휴먼 소팅..ㅠ"]},{"cell_type":"code","metadata":{"id":"TJG475KW6Eoy","colab_type":"code","colab":{}},"source":["import re\n","\n","def atoi(text):\n","    return int(text) if text.isdigit() else text\n","\n","def natural_keys(text):\n","    '''\n","    alist.sort(key=natural_keys) sorts in human order\n","    http://nedbatchelder.com/blog/200712/human_sorting.html\n","    (See Toothy's implementation in the comments)\n","    '''\n","    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IGKQgENQ8lEI","colab":{}},"source":["anim_file = OUTPUT_DIR + 'dcgan_simsons_faces_masa.gif'\n","\n","with imageio.get_writer(anim_file, mode='I') as writer:\n","    \n","    filenames = glob(OUTPUT_DIR+'images/15_*.png')\n","    filenames = sorted(filenames)\n","    filenames.sort(key=natural_keys)\n","    \n","    last = -1\n","    for i,filename in enumerate(filenames):\n","        # frame = 2*(i**0.5)\n","        # if round(frame) > round(last):\n","        #     last = frame\n","        # else:\n","        #     continue\n","        \n","        # image = imageio.imread(filename)\n","        # writer.append_data(image)\n","        \n","        image = imageio.imread(filename)\n","        writer.append_data(image)\n","\n","\n","\n","import IPython\n","\n","if IPython.version_info > (6,2,0,''):\n","    display.Image(filename=anim_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0UskDYd9Fvrj","colab_type":"code","colab":{}},"source":["anim_lfile = OUTPUT_DIR + 'dcgan_loss.gif'\n","\n","with imageio.get_writer(anim_lfile, mode='I') as writer:\n","    \n","    filenames = glob(OUTPUT_LOSS_DIR+'losses_*.png')\n","    filenames = sorted(filenames)\n","    filenames.sort(key=natural_keys)\n","    \n","    # last = -1\n","    for i,filename in enumerate(filenames):\n","        # frame = 2*(i**0.5)\n","        # if round(frame) > round(last):\n","        #     last = frame\n","        # else:\n","        #     continue\n","        \n","        # image = imageio.imread(filename)\n","        # writer.append_data(image)\n","        \n","        image = imageio.imread(filename)\n","        writer.append_data(image)\n","\n","import IPython\n","\n","if IPython.version_info > (6,2,0,''):\n","    display.Image(filename=anim_lfile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uV0yiKpzNP1b","colab":{}},"source":["try:\n","    from google.colab import files\n","except ImportError:\n","    pass\n","else:\n","    files.download(anim_file)"],"execution_count":0,"outputs":[]}]}